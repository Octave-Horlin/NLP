{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "%pip install transformers>=4.41 accelerate datasets sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the rotten_tomatoes dataset\n",
        "dataset = load_dataset(\"rotten_tomatoes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the DatasetDict structure\n",
        "print(dataset)\n",
        "print(f\"\\nTrain: {len(dataset['train'])} rows\")\n",
        "print(f\"Validation: {len(dataset['validation'])} rows\")\n",
        "print(f\"Test: {len(dataset['test'])} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a task-specific model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_texts = dataset[\"test\"][\"text\"]\n",
        "test_labels = dataset[\"test\"][\"label\"]\n",
        "\n",
        "predictions = []\n",
        "for text in tqdm(test_texts, desc=\"Running inference\"):\n",
        "    result = classifier(text)[0]\n",
        "    score = result[\"score\"]\n",
        "    label = result[\"label\"].lower()\n",
        "    \n",
        "    if \"positive\" in label:\n",
        "        pred = 1\n",
        "    else:\n",
        "        pred = 0\n",
        "    \n",
        "    predictions.append(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(test_labels, predictions, target_names=[\"negative\", \"positive\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification tasks with embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A) Supervised classification with embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_texts = dataset[\"train\"][\"text\"]\n",
        "train_labels = dataset[\"train\"][\"label\"]\n",
        "test_texts = dataset[\"test\"][\"text\"]\n",
        "test_labels = dataset[\"test\"][\"label\"]\n",
        "\n",
        "train_embeddings = model.encode(train_texts, show_progress_bar=True)\n",
        "test_embeddings = model.encode(test_texts, show_progress_bar=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(train_embeddings, train_labels)\n",
        "predictions = classifier.predict(test_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(test_labels, predictions, target_names=[\"negative\", \"positive\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B) Unsupervised use case\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "train_embeddings_neg = train_embeddings[train_labels == 0]\n",
        "train_embeddings_pos = train_embeddings[train_labels == 1]\n",
        "\n",
        "class_centroid_neg = train_embeddings_neg.mean(axis=0)\n",
        "class_centroid_pos = train_embeddings_pos.mean(axis=0)\n",
        "\n",
        "class_centroid_neg = np.nan_to_num(class_centroid_neg, nan=0.0)\n",
        "class_centroid_pos = np.nan_to_num(class_centroid_pos, nan=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "centroids = np.vstack([class_centroid_neg, class_centroid_pos])\n",
        "test_embeddings_clean = np.nan_to_num(test_embeddings, nan=0.0)\n",
        "similarities = cosine_similarity(test_embeddings_clean, centroids)\n",
        "predictions = similarities.argmax(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(test_labels, predictions, target_names=[\"negative\", \"positive\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C) Zero-shot classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_descriptions = [\"A negative review\", \"A positive review\"]\n",
        "label_embeddings = model.encode(label_descriptions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "similarities = cosine_similarity(test_embeddings, label_embeddings)\n",
        "predictions = similarities.argmax(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(test_labels, predictions, target_names=[\"negative\", \"positive\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text classification with generative models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install groq python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**To set your Groq API key:**\n",
        "\n",
        "**Option 1 (Recommended):** Use Colab Secrets\n",
        "- Click the ðŸ”‘ key icon in the left sidebar\n",
        "- Add a new secret: `GROQ_API_KEY` = `your-api-key`\n",
        "\n",
        "**Option 2:** Uncomment and set directly in the cell below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and set your Groq API key here:\n",
        "# os.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key-here\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Try to get API key from Colab secrets first\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Check if API key is set\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Please set it using Colab secrets (recommended) or uncomment the line in the cell above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\") or os.environ[\"GROQ_API_KEY\"] == \"\":\n",
        "    raise ValueError(\"GROQ_API_KEY is not set. Please configure it in the previous cell.\")\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def groq_predict(text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a sentiment classifier. Respond with 'positive' or 'negative' only.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Classify the sentiment of this movie review: {text}\"}\n",
        "        ],\n",
        "        temperature=0.1,\n",
        "        max_tokens=10\n",
        "    )\n",
        "    prediction = response.choices[0].message.content.strip().lower()\n",
        "    if \"positive\" in prediction:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"negative\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_texts = dataset[\"test\"][\"text\"]\n",
        "test_labels = dataset[\"test\"][\"label\"]\n",
        "\n",
        "predictions = []\n",
        "for text in tqdm(test_texts, desc=\"Running Groq predictions\"):\n",
        "    pred = groq_predict(text)\n",
        "    predictions.append(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_mapped = [1 if p == \"positive\" else 0 for p in predictions]\n",
        "print(classification_report(test_labels, predictions_mapped, target_names=[\"negative\", \"positive\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text2Text transfert transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "t5_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_t5_prompt(example):\n",
        "    prompt = \"Is the following sentence positive or negative? \"\n",
        "    example[\"t5\"] = prompt + example[\"text\"]\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(add_t5_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_t5 = dataset[\"test\"][\"t5\"]\n",
        "test_labels = dataset[\"test\"][\"label\"]\n",
        "\n",
        "predictions = []\n",
        "for text in tqdm(test_t5, desc=\"Running T5 inference\"):\n",
        "    result = t5_pipeline(text, max_length=10)[0][\"generated_text\"]\n",
        "    predictions.append(result.strip().lower())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_mapped = []\n",
        "for pred in predictions:\n",
        "    if \"positive\" in pred:\n",
        "        predictions_mapped.append(1)\n",
        "    else:\n",
        "        predictions_mapped.append(0)\n",
        "\n",
        "print(classification_report(test_labels, predictions_mapped, target_names=[\"negative\", \"positive\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This lab explored multiple approaches to text classification, demonstrating the trade-offs between different methods. Task-specific models like RoBERTa fine-tuned for sentiment analysis typically achieve the highest performance by leveraging domain-specific training. Supervised classification with embeddings offers a flexible alternative that combines pre-trained representations with task-specific classifiers. Unsupervised centroid-based methods provide a simple baseline without requiring labeled data, while zero-shot classification with label descriptions enables classification without training examples. Generative LLMs via API calls offer flexibility and ease of use but may be slower and more expensive. Text2Text transformers like T5 demonstrate how sequence-to-sequence models can be adapted for classification tasks through prompting. The choice of method depends on factors such as available training data, computational resources, latency requirements, and desired accuracy.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
